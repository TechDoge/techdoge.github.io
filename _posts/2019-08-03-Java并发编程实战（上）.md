---

layout:     post
title:     Java并发编程实战（上）
subtitle:   
date:       2019-07-21
author:     ctrlcoder
header-img: 
catalog: true
tags:
    - 并发编程
typora-root-url: ..
---

![图片](https://uploader.shimo.im/f/vnfcYnV7SqYEvsgD.png!thumbnail)

# 01 | 可见性、原子性和有序性问题：并发编程Bug的源头

- 缓存导致的可见性问题
- 线程切换带来的原子性问题
- 编译优化带来的有序性问题

 

1. **可见性**：多核系统每个cpu自带高速缓存，彼此间不交换信息（列子：两个线程对同一份实列变量count累加，结果可能不等于累加之和，因为线程将内存值载入各自的缓存中，之后的累加操作基于缓存值进行，并不是累加一次往内存回写一次）
2. **原子性**：cpu分时操作导致线程的切换，（列子：AB两个线程同时进行count+=1，由于+=操作是3步指令①从内存加载②+1操作③回写到主内，线程A对其进行了①②操作后，切换到B线程，B线程进行了①②③，这时内存值是1，然后再切到A执行③操作，这时的值也还是1，PS:这貌似也存在可见性的问题）
3. **有序性**：指令的重排序（列子：单列模式的双重检测，new指令也是3步操作，①分内存②初始化③赋值给引用变量，可能会发生①③②的重排序，这时候如果又有操作系统的分时操作的加持，导致A操作①③后挂起，时间片被分配给了B线程，而B线程甚至都不需要进行锁的获取，因为此时instance已经不等于null了，但是此时的instance可能未初始化）

**在 32 位的机器上对 long 型变量进行加减操作存在并发隐患**
在32位系统对32位变量读写是原子操作,但是long是64,所以是非原子操作,简单的说，在32位操作系统上，对64位的数据的读写是分两步的，一步取前32位数据，一步取后32位数据，通过这两步操作来实现对64位数据的读写.

# 02 | Java内存模型：看Java如何解决可见性和有序性问题

为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。

## 使用 volatile 的困惑

```java
class VolatileExample {
  int x = 0;
  **volatile **boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }
  public void reader() {
    if (v == true) {
      // 这里 x 会是多少呢？
    }
  }
}
```

分析一下，为什么 1.5 以前的版本会出现 x = 0 的情况呢？我相信你一定想到了，变量 x 可能被 CPU 缓存而导致可见性问题。这个问题在 1.5 版本已经被圆满解决了。Java 内存模型在 1.5 版本对 volatile 语义进行了增强。怎么增强的呢？答案是一项 Happens-Before。

## Happens-Before 规则

**1. 程序的顺序性规则**
这条规则是指在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作。
**2. volatile 变量规则**
这条规则是指对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile 变量的读操作。
**3. 传递性**
这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-Before C。
![图片](/img/assets_2019/image-1564798351168.png__thumbnail)

根据这个传递性规则，我们得到结果：“x=42” Happens-Before 读变量“v=true”。这意味着什么呢？如果线程 B 读到了“v=true”，那么线程 A 设置的“x=42”对线程 B 是可见的。也就是说，线程 B 能看到 “x == 42” ，有没有一种恍然大悟的感觉？这就是 1.5 版本对 volatile 语义的增强，这个增强意义重大，1.5 版本的并发工具包（java.util.concurrent）就是靠 volatile 语义来搞定可见性的，这个在后面的内容中会详细介绍。

**4. 管程中锁的规则**
要理解这个规则，就首先要了解“管程指的是什么”。是一种通用的同步原语，在 Java 中指的就是 synchronized，synchronized 是 Java 里对管程的实现。管程中的锁在 Java 里是隐式实现的，例如下面的代码，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。

**5. 线程 start() 规则**
这条是关于线程启动的。它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在启动子线程 B 前的操作。换句话说就是，如果线程 A 调用线程 B 的 start() 方法（即在线程 A 中启动线程 B），那么该 start() 操作 Happens-Before 于线程 B 中的任意操作。具体可参考下面示例代码。

**6. 线程 join() 规则**
这条是关于线程等待的。它是指主线程 A 等待子线程 B 完成（主线程 A 通过调用子线程 B 的 join() 方法实现），当子线程 B 完成后（主线程 A 中 join() 方法返回），主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作。换句话说就是，如果在线程 A 中，调用线程 B 的 join() 并成功返回，那么线程 B 中的任意操作 Happens-Before 于该 join() 操作的返回。具体可参考下面示例代码。

## 被我们忽视的 final

final 修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化。Java 编译器在 1.5 以前的版本的确优化得很努力，以至于都优化错了，构造函数的错误重排导致线程可能看到 final 变量的值会变化。
当然了，在 1.5 以后 Java 内存模型对 final 类型变量的重排进行了约束。现在只要我们提供正确构造函数没有“逸出”，就不会出问题了。

**有一个共享变量 abc，在一个线程里设置了 abc 的值 abc=3，你思考一下，有哪些办法可以让其他线程能够看到abc==3？**

1. 使用volatile修饰abc -禁止cpu缓存直接从内存获取和volatile写 happens before volatile读。
2. synchronized 代码块中操作abc 解锁happens before 加锁。
3. 线程A操作共享变量abc然后start方法启动B线程 B线程中可见abc操作。
4. 线程A操作共享变量abc，B join A 对于B线程可见。





# 03 | 互斥锁（上）：解决原子性问题

“同一时刻只有一个线程执行”这个条件非常重要，我们称之为互斥。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。
![图片](/img/assets_2019/image-1564798358243.png__thumbnail)
我们把一段需要互斥执行的代码称为临界区。线程在进入临界区之前，首先尝试加锁lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则呢就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁 unlock()。
![图片](/img/assets_2019/image-1564798362604.png__thumbnail)
首先，我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。

## Java 语言提供的锁技术：synchronized

Java 编译器会在 synchronized 修饰的方法或代码块前后自动加上加锁lock() 和解锁 unlock()，这样做的好处就是加锁 lock() 和解锁 unlock() 一定是成对出现的，毕竟忘记解锁 unlock() 可是个致命的 Bug（意味着其他线程只能死等下去了）

- 当修饰静态方法的时候，锁定的是当前类的 Class 对象，在上面的例子中就是 Class X；
- 当修饰非静态方法的时候，锁定的是当前实例对象 this。

管程，就是我们这里的 synchronized（至于为什么叫管程，我们后面介绍），我们知道synchronized 修饰的临界区是互斥的，也就是说同一时刻只有一个线程执行临界区的代码；而所谓“对一个锁解锁 Happens-Before 后续对这个锁的加锁”，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合 Happens-Before 的传递性原则，我们就能得出前一个线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。

## 锁和受保护资源的关系

受保护资源和锁之间的关联关系是 N:1 的关系，也就是说可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源

# 04 | 互斥锁（下）：如何用一把锁保护多个资源？

## 保护没有关联关系的多个资源

用一把锁有个问题，就是性能太差，会导致取款、查看余额、修改密码、查看密码这四个操作都是串行的。而我们用两把锁，取款和修改密码是可以并行的。用不同的锁对受保护资源进行精细化管理，能够提升性能。这种锁还有个名字，叫细粒度锁。

## 保护有关联关系的多个资源

使用锁的正确姿势

我们把 Account 默认构造函数变为 private，同时增加一个带 Object lock 参数的构造函数，创建 Account 对象时，传入相同的 lock，这样所有的 Account 对象都会共享这个lock 了。

在真实的项目场景中，创建 Account 对象的代码很可能分散在多个工程中，传入共享的 lock 真的很难。所以，上面的方案缺乏实践的可行性，我们需要更好的方案。还真有，就是用Account.class 作为共享的锁。Account.class 是所有 Account 对象共享的，而且这个对象是 Java 虚拟机在加载 Account 类的时候创建的，所以我们不用担心它的唯一性。使用Account.class 作为共享的锁，我们就无需在创建 Account 对象时传入了，代码更简单。

“原子性”的本质是什么？其实不是不可分割，不可分割只是外在表现，其本质是多个资源间有一致性的要求，操作的中间状态对外不可见。例如，在 32 位的机器上写 long 型变量有中间状态（只写了 64 位中的 32 位），在银行转账的操作中也有中间状态（账户 A减少了 100，账户 B 还没来得及发生变化）。所以解决原子性问题，是要保证中间状态对外不可见。



# 05 | 一不小心就死锁了，怎么办？

怎么发生死锁的呢？我们假设线程 T1 执行账户 A 转账户 B 的操作，账户A.transfer(账户 B)；同时线程 T2 执行账户 B 转账户 A 的操作，账户 B.transfer(账户 A)。当 T1和 T2 同时执行完①处的代码时，T1 获得了账户 A 的（对于 T1，this 是账户 A），而 T2 获得了账户 B 的锁（对于 T2，this 是账户 B）。之后 T1 和 T2 在执行②处的代码时，T1 试图获取账户 B 的锁时，发现账户 B 已经被锁定（被 T2 锁定），所以 T1 开始等待；T2 则试图获取账户 A 的锁时，发现账户 A 已经被锁定（被 T1 锁定），所以 T2 也开始等待。于是 T1 和 T2 会无期限地等待下去，也就是我们所说的死锁了。
![图片](/img/assets_2019/image-1564798368567.png__thumbnail)

那如何避免死锁呢？要避免死锁就需要分析死锁发生的条件，有个叫 Coffman 的牛人早就总结
过了，只有以下这四个条件都发生时才会出现死锁：

1. 互斥，共享资源 X 和 Y 只能被一个线程占用；
2. 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
3. 不可抢占，其他线程不能强行抢占线程 T1 占有的资源；
4. 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等

待。

反过来分析，**也就是说只要我们破坏其中一个，就可以成功避免死锁的发生。**

**互斥这个条件我们没有办法破坏，因为我们用锁为的就是互斥。不过其他三个条件都是有办法破坏掉的，到底如何做呢？**

**1. 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。**
**2. 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以**
***主动释放它占有的资源，这样不可抢占这个条件就破坏掉了****。*

*破坏不可抢占条件看上去很简单，核心是要能够主动释放它占有的资源，这一点 synchronized*
*是做不到的。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态*
*了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。*
*你可能会质疑，“Java 作为排行榜第一的语言，这都解决不了？”你的怀疑很有道理，Java 在*
*语言层次确实没有解决这个问题，不过在 SDK 层面还是解决了的，java.util.concurrent 这个包*
*下面提供的 Lock 是可以轻松解决这个问题的。关于这个话题，咱们后面会详细讲。*

**3. 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。**



# 06 | 用“等待-通知”机制优化循环等待

一个完整的等待 - 通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程重新获取互斥锁通知等待的线程，重新获取互斥锁。在 Java 语言里，等待 - 通知机制可以有多种实现方式，比如 Java 语言内置的 synchronized 配合 wait()、notify()、notifyAll() 这三个方法就能轻松实现。
如何用 synchronized 实现互斥锁，你应该已经很熟悉了。在下面这个图里，左边有一个等待队列，同一时刻，只允许一个线程进入 synchronized 保护的临界区（这个临界区可以看作大夫的诊室），当有一个线程进入临界区后，其他线程就只能进入图中左边的等待队列里等待（相当于患者分诊等待）。这个等待队列和互斥锁是一对一的关系，每个互斥锁都有自己独立的等待队列。
![图片](/img/assets_2019/image-1564798378695.png__thumbnail)
在并发程序中，当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态，Java 对象的 wait() 方法就能够满足这种需求。如上图所示，当调用 wait() 方法后，当前线程就会被阻塞，并且进入到右边的等待队列中，这个等待队列也是互斥锁的等待队列。 线程在进入等待队列的同时，会释放持有的互斥锁，线程释放锁后，其他线程就有机会获得锁，并进入临界区了。
![](/img/assets_2019/image-1564798385215.png__thumbnail)
**那线程要求的条件满足时，该怎么通知这个等待的线程呢？**很简单，就是 Java 对象的 notify()和 notifyAll() 方法。我在下面这个图里为你大致描述了这个过程，当条件满足时调用 notify()，会通知等待队列（互斥锁的等待队列）中的线程，告诉它条件曾经满足过。

为什么说是曾经满足过呢？因为**notify() 只能保证在通知时间点，条件是满足的**。而被通知线程的执行时间点和通知的时间点基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）。这一点你需要格外注意。除此之外，还有一个需要注意的点，被通知的线程要想重新执行，仍然需要获取到互斥锁（因为曾经获取的锁在调用 wait() 时已经释放了）

上面我们一直强调 wait()、notify()、notifyAll() 方法操作的等待队列是互斥锁的等待队列，所以
如果 synchronized 锁定的是 this，那么对应的一定是 this.wait()、this.notify()、this.notifyAll()；而且 wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，所以我们会发现 wait()、notify()、notifyAll() 都是在synchronized{}内部被调用的。如果在synchronized{}外部调用，或者锁定的 this，而target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。

在上面的代码中，我用的是 notifyAll() 来实现通知机制，为什么不使用 notify() 呢？这二者是有区别的，**notify() 是会随机地通知等待队列中的一个线程，而 notifyAll() 会通知等待队列中的所有线程**。从感觉上来讲，应该是 notify() 更好一些，因为即便通知所有线程，也只有一个线程能够进入临界区。但那所谓的感觉往往都蕴藏着风险，实际上使用 notify() 也很有风险，它的风险在于可能导致某些线程永远不会被通知到。



# 07 | 安全性、活跃性以及性能问题

理论上**线程安全**的程序，就要避免出现原子性问题、可见性问题和有序性问题。那是不是所有的代码都需要认真分析一遍是否存在这三个问题呢？当然不是，其实只有一种情况需要：存在共享数据并且该数据会发生变化，通俗地讲就是有多个线程会同时读写同一数据。

所谓**活跃性**问题，指的是某个操作无法执行下去。我们常见的“死锁”就是一种典型的活跃性问题，当然除了死锁外，还有两种情况，分别是“活锁”和“饥饿”。解决“**活锁**”的方案很简单，谦让时，尝试等待一个随机的时间就可以了。那“**饥饿**”该怎么去理解呢？所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况。“不患寡，而患不均”，如果线程优先级“不均”，在 CPU 繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。

那如何公平地分配资源呢？在并发编程里，主要是使用公平锁。所谓公平锁，是一种先来后到的方案，线程的等待是有顺序的，排在等待队列前面的线程会优先获得资源。

使用“锁”要非常小心，但是如果小心过度，也可能出“性能问题”。“锁”的过度使用可能导致串行化的范围过大，这样就不能够发挥多线程的优势了，而我们之所以使用多线程搞并发程序，为的就是提升性能。
Java SDK 并发包里之所以有那么多东西，有很大一部分原因就是要提升在某个特定领域的性能。

不过从方案层面，我们可以这样来解决这个问题。

第一，既然使用锁会带来性能问题，那最好的方案自然就是使用无锁的算法和数据结构了。在这
方面有很多相关的技术，例如线程本地存储 (Thread Local Storage, TLS)、写入时复制(Copyon-write)、乐观锁等；Java 并发包里面的原子类也是一种无锁的数据结构；Disruptor 则是一个无锁的内存队列，性能都非常好……

第二，减少锁持有的时间。互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减
少持有锁的时间。这个方案具体的实现技术也有很多，例如使用细粒度的锁，一个典型的例子就
是 Java 并发包里的 ConcurrentHashMap，它使用了所谓分段锁的技术（这个技术后面我们会
详细介绍）；还可以使用读写锁，也就是读是无锁的，只有写的时候才会互斥。



性能方面的度量指标有很多，我觉得有三个指标非常重要，就是：吞吐量、延迟和并发量。

1. 吞吐量：指的是单位时间内能处理的请求数量。吞吐量越高，说明性能越好。
2. 延迟：指的是从发出请求到收到响应的时间。延迟越小，说明性能越好。
3. 并发量：指的是能同时处理的请求数量，一般来说随着并发量的增加、延迟也会增加。所以延迟这个指标，一般都会是基于并发量来说的。例如并发量是 1000 的时候，延迟是 50 毫秒。



# 08 | 管程：并发编程的万能钥匙

管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器”，这是直译。操作系统领域一般都翻译成“管程”，这个是意译，而我自己也更倾向于使用“管程”。

在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA模型。所以今天我们重点介绍一下 MESA 模型。

在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。

**我们先来看看管程是如何解决互斥问题的。**

管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。

**那管程如何解决线程间的同步问题呢？**
管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量A 和条件变量 B 分别都有自己的等待队列。
![](/img/assets_2019/image-1564798391391.png__thumbnail)

但是有一点，需要再次提醒，对于 MESA 管程来说，有一个编程范式，就是需要在一个 while 循环里面调用 wait()。这个是 MESA 管程特有的。

MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是当 T1 再次执行的时候，可能曾经满足的条件，现在已经不满足了，所以需要以循环方式检验条件变量。



# 09 | Java线程（上）：Java线程的生命周期

通用的线程生命周期基本上可以用下图这个“五态模型”来描述。这五态分别是：初始状态、可
运行状态、运行状态、休眠状态和终止状态。
![](/img/assets_2019/image-1564798395044.png__thumbnail)



**Java 语言中线程共有六种状态，分别是：**

1. NEW（初始化状态）
2. RUNNABLE（可运行 / 运行状态）
3. BLOCKED（阻塞状态）
4. WAITING（无时限等待）
5. TIMED_WAITING（有时限等待）
6. TERMINATED（终止状态）

这看上去挺复杂的，状态类型也比较多。但其实在操作系统层面，Java 线程中的 BLOCKED、
WAITING、TIMED_WAITING 是一种状态，即前面我们提到的休眠状态。也就是说**只要 Java**
**线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。**
![](/img/assets_2019/wCe4Um9vIC8PTNFQ__thumbnail-1564798398335)

**1. RUNNABLE 与 BLOCKED 的状态转换**
只有一种场景会触发这种转换，就是线程等待 synchronized 的隐式锁。synchronized 修饰的方法、代码块同一时刻只允许一个线程执行，其他线程只能等待，这种情况下，等待的线程就会从 RUNNABLE 转换到 BLOCKED 状态。而当等待的线程获得 synchronized 隐式锁时，就又会从 BLOCKED 转换到 RUNNABLE 状态。

如果你熟悉操作系统线程的生命周期的话，可能会有个疑问：线程调用阻塞式 API 时，是否会转换到 BLOCKED 状态呢？在操作系统层面，线程是会转换到休眠状态的，但是在 JVM 层面，

 请勿倒卖Java 线程的状态不会发生变化，也就是说 Java 线程的状态会依然保持 RUNNABLE 状态。JVM层面并不关心操作系统调度相关的状态，因为在 JVM 看来，等待 CPU 使用权（操作系统层面此时处于可执行状态）与等待 I/O（操作系统层面此时处于休眠状态）没有区别，都是在等待某个资源，所以都归入了 RUNNABLE 状态。

而我们平时所谓的 Java 在调用阻塞式 API 时，线程会阻塞，指的是操作系统线程的状态，并不是 Java 线程的状态。

**2. RUNNABLE 与 WAITING 的状态转换**
总体来说，有三种场景会触发这种转换。
第一种场景，获得 synchronized 隐式锁的线程，调用无参数的 Object.wait() 方法。其中，wait() 方法我们在上一篇讲解管程的时候已经深入介绍过了，这里就不再赘述。

第二种场景，调用无参数的 Thread.join() 方法。其中的 join() 是一种线程同步方法，例如有一个线程对象 thread A，当调用 A.join() 的时候，执行这条语句的线程会等待 thread A 执行完，而等待中的这个线程，其状态会从 RUNNABLE 转换到 WAITING。当线程 thread A 执行完，原来等待它的线程又会从 WAITING 状态转换到 RUNNABLE。

第三种场景，调用 LockSupport.park() 方法。其中的 LockSupport 对象，也许你有点陌生，其实 Java 并发包中的锁，都是基于它实现的。调用 LockSupport.park() 方法，当前线程会阻塞，线程的状态会从 RUNNABLE 转换到 WAITING。调用 LockSupport.unpark(Thread thread) 可唤醒目标线程，目标线程的状态又会从 WAITING 状态转换到 RUNNABLE。

**3. RUNNABLE 与 TIMED_WAITING 的状态转换**
有五种场景会触发这种转换：

1. 调用带超时参数的 Thread.sleep(long millis) 方法；
2. 获得 synchronized 隐式锁的线程，调用带超时参数的 Object.wait(long timeout) 方法；
3. 调用带超时参数的 Thread.join(long millis) 方法；
4. 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法；
5. 调用带超时参数的 LockSupport.parkUntil(long deadline) 方法。

这里你会发现 TIMED_WAITING 和 WAITING 状态的区别，仅仅是触发条件多了超时参数。

**4. 从 NEW 到 RUNNABLE 状态**
Java 刚创建出来的 Thread 对象就是 NEW 状态，而创建 Thread 对象主要有两种方法。一种是
继承 Thread 对象，重写 run() 方法。
另一种是实现 Runnable 接口，重写 run() 方法，并将该实现类作为创建 Thread 对象的参数。

NEW 状态的线程，不会被操作系统调度，因此不会执行。Java 线程要执行，就必须转换到RUNNABLE 状态。从 NEW 状态转换到 RUNNABLE 状态很简单，只要调用线程对象的 start()方法就可以了

**5. 从 RUNNABLE 到 TERMINATED 状态**
线程执行完 run() 方法后，会自动转换到 TERMINATED 状态，当然如果执行 run() 方法的时候异常抛出，也会导致线程终止。有时候我们需要强制中断 run() 方法的执行，例如 run() 方法访问一个很慢的网络，我们等不下去了，想终止怎么办呢？Java 的 Thread 类里面倒是有个 stop()方法，不过已经标记为 @Deprecated，所以不建议使用了。正确的姿势其实是调用 interrupt()方法。
**那 stop() 和 interrupt() 方法的主要区别是什么呢？**

当线程 A 处于 WAITING、TIMED_WAITING 状态时，如果其他线程调用线程 A 的 interrupt()方法，会使线程 A 返回到 RUNNABLE 状态，同时线程 A 的代码会触发 InterruptedException异常。上面我们提到转换到 WAITING、TIMED_WAITING 状态的触发条件，都是调用了类似wait()、join()、sleep() 这样的方法，我们看这些方法的名，发现都会 throws InterruptedException 这个异常。这个异常的触发条件就是：其他线程调用了该线程的interrupt() 方法。

当线程 A 处于 RUNNABLE 状态时，并且阻塞在 java.nio.channels.InterruptibleChannel 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 会触发java.nio.channels.ClosedByInterruptException 这个异常；而阻塞在java.nio.channels.Selector 上时，如果其他线程调用线程 A 的 interrupt() 方法，线程 A 的java.nio.channels.Selector 会立即返回。

上面这两种情况属于被中断的线程通过异常的方式获得了通知。还有一种是主动检测，如果线程处于 RUNNABLE 状态，并且没有阻塞在某个 I/O 操作上，例如中断计算圆周率的线程 A，这时就得依赖线程 A 主动检测中断状态了。如果其他线程调用线程 A 的 interrupt() 方法，那么线程A 可以通过 isInterrupted() 方法，检测是不是自己被中断了。

# 10 | Java线程（中）：创建多少线程才是合适的？

度量性能的指标有很多，但是有两个指标是最核心的，它们就是延迟和吞吐量。延迟指的是发出请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好。 吞吐指的是在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越好。这两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。

要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，一个方向是优化算法，另一个方向是将硬件的性能发挥到极致。前者属于算法范畴，后者则是和并发编程息息相关了。那计算机主要有哪些硬件呢？主要是两类：一个是 I/O，一个是 CPU。简言之，在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用率。

**最佳线程数 =CPU 核数 * [ 1 +（I/O 耗时 / CPU 耗时）]**

# 11| Java线程（下）：为什么局部变量是线程安全的？

局部变量就是放到了调用栈里

每个线程都有自己独立的调用栈

方法里的局部变量，因为不会和其他线程共享，所以没有并发问题，这个思路很好，已经成为解
决并发问题的一个重要技术，同时还有个响当当的名字叫做**线程封闭**，比较官方的解释是：**仅在**
**单线程内访问数据**。由于不存在共享，所以即便不同步也不会有并发问题，性能杠杠的。

采用线程封闭技术的案例非常多，例如从数据库连接池里获取的连接 Connection，在 JDBC 规
范里并没有要求这个 Connection 必须是线程安全的。数据库连接池通过线程封闭技术，保证一
个 Connection 一旦被一个线程获取之后，在这个线程关闭 Connection 之前的这段时间里，不
会再分配给其他线程，从而保证了 Connection 不会有并发问题。

# **12 | 如何用面向对象思想写好并发程序？**

## 一、封装共享变量

面向对象思想里面有一个很重要的特性是封装，封装的通俗解释就是将属性和实现细节封装在对
象内部，外界对象只能通过目标对象提供的公共方法来间接访问这些内部属性。

利用面向对象思想写并发程序的思路，其实就这么简单：**将共享变量作为对象属性封装在内部**，
**对所有公共方法制定并发访问策略。**

对于这些不会发生变化的共享变量，建议你用 final 关键字来修饰，这样能避免并发问题。

## 二、识别共享变量间的约束条件

**约束条件，决定了并发访问策略**
一定要识别出所有共享变量之间的约束条件，如果约束条件识别不足，很可能导致制定
的并发访问策略南辕北辙。

## 三、制定并发访问策略

制定并发访问策略，是一个非常复杂的事情。应该说整个专栏都是在尝试搞定它。不过从方案上
来看，无外乎就是以下“三件事”。

1.  **避免共享**：避免共享的技术主要是利于线程本地存储以及为每个任务分配独立的线程。

2. ** 不变模式**：这个在 Java 领域应用的很少，但在其他领域却有着广泛的应用，例如 Actor 模
   式、CSP 模式以及函数式编程的基础都是不变模式。

3.  **管程及其他同步工具**：Java 领域万能的解决方案是管程，但是对于很多特定场景，使用 Java并发包提供的读写锁、并发容器等同步工具会更好。

除了这些方案之外，还有一些宏观的原则需要你了解。这些宏观原则，有助于你写出“健壮”的
并发程序。这些原则主要有以下三条。

1. **优先使用成熟的工具类**：Java SDK 并发包里提供了丰富的工具类，基本上能满足你日常的需
   要，建议你熟悉它们，用好它们，而不是自己再“发明轮子”，毕竟并发工具类不是随随便便
   就能发明成功的。

2. **迫不得已时才使用低级的同步原语**：低级的同步原语主要指的是 synchronized、Lock、Semaphore 等，这些虽然感觉简单，但实际上并没那么简单，一定要小心使用。

3. **避免过早优化**：安全第一，并发程序首先要保证安全，出现性能瓶颈后再优化。在设计期和开发期，很多人经常会情不自禁地预估性能的瓶颈，并对此实施优化，但残酷的现实却是：性能瓶颈不是你想预估就能预估的。

![](/img/assets_2019/image-1564798407106.png__thumbnail)