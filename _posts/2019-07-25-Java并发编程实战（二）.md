---

layout:     post
title:     Java并发编程实战（二）
subtitle:   
date:       2019-07-25
author:     ctrlcoder
header-img: 
catalog: true
tags:
    - 并发编程
typora-root-url: ..
---

![图片](/img/assets_2019/image-1564904974717.png__thumbnail)

## 14 | Lock&Condition（上）：隐藏在并发包中的管程

并发编程领域，有两大核心问题：一个是**互斥**，即同一时刻只允许一个线程访问共享资源；另一个是**同步**，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。**Java SDK 并发包通过 Lock 和 Condition 两个接口来实现管程，其中 Lock 用于解决互斥问题，Condition 用于解决同步问题**。



说，例如在 Java 的 1.5 版本中，synchronized 性能不如 SDK 里面的 Lock，但 1.6 版本之后，synchronized 做了很多优化，将性能追了上来，所以 1.6 之后的版本又有人推荐使用 synchronized 了。那性能是否可以成为“重复造轮子”的理由呢？ 

Synchronized 申请资源的时候，如果申请不到，线程直 接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。但我们希望的是： 

> 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申 请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 

 

如果我们重新设计一把互斥锁去解决这个问题，那该怎么设计呢？我觉得有三种方案。 

1. **能够响应中断**。synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就 进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能 够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有 机会释放曾经持有的锁 A。这样就破坏了不可抢占条件了。 

2. **支持超时**。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误， 那这个线程也有机会释放曾经持有的锁。这样也能破坏不可抢占条件。 

3. **非阻塞地获取锁**。如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有 机会释放曾经持有的锁。这样也能破坏不可抢占条件。 

这三种方案可以全面弥补 synchronized 的问题。到这里相信你应该也能理解了，这三个方案就是“重复造轮子”的主要原因，体现在 API 上，就是 Lock 接口的三个方法。详情如下：

```java
// 支持中断的 API 

void lockInterruptibly()  throws InterruptedException; 

// 支持超时的 API 

boolean tryLock(long time, TimeUnit unit)  throws InterruptedException; 

// 支持非阻塞获取锁的 API 

boolean tryLock(); 
```

### **如何保证可见性**

Java SDK 里面 Lock 的使用，有一个经典的范例，就是try{}finally{} ，需要重点关注的是在 finally 里面释放锁。这个范例无需多解释，你看一下下面的代码就明白 了。但是有一点需要解释一下，那就是可见性是怎么保证的。你已经知道 Java 里多线程的可见 性是通过 Happens-Before 规则保证的，而 synchronized 之所以能够保证可见性，也是因为有一条 synchronized 相关的规则：synchronized 的解锁 Happens-Before 于后续对这个锁的加 锁。

那 Java SDK 里面 Lock 靠什么保证可见性呢？例如在下面的代码中，线程 T1 对 value 进 行了 +=1 操作，那后续的线程 T2 能够看到 value 的正确结果吗？ 

```java
class X { 
 private final Lock rtl =  new ReentrantLock(); 
 int value; 
 public void addOne() { 
 // 获取锁 
 rtl.lock();  
 try { 
 value+=1; 
 } finally { 
 // 保证锁能释放 
 rtl.unlock(); 
 } 
 } 
} 
```

答案必须是肯定的。**Java SDK 里面锁**的实现非常复杂，这里我就不展开细说了，但是原理还是 需要简单介绍一下：它是**利用了 volatile 相关的 Happens-Before 规则**。Java SDK 里面的 ReentrantLock，内部持有一个 volatile 的成员变量 state，获取锁的时候，会读写 state 的值； 解锁的时候，也会读写 state 的值（简化后的代码如下面所示）。也就是说，在执行 value+=1 之前，程序先读写了一次 volatile 变量 state，在执行 value+=1 之后，又读写了一次 volatile 变量 state。根据相关的 Happens-Before 规则：

1. **顺序性规则**：对于线程 T1，value+=1 Happens-Before 释放锁的操作 unlock()； 

2. **volatile 变量规则**：由于 state = 1 会先读取 state，所以线程 T1 的 unlock() 操作 Happens-Before 线程 T2 的 lock() 操作； 

3. **传递性规则**：线程 T2 的 lock() 操作 Happens-Before 线程 T1 的 value+=1 。 

```java
 class SampleLock { 
 volatile int state; 
 // 加锁 
 lock() { 
 // 省略代码无数 
 state = 1; 
 } 
 // 解锁 
 unlock() { 
 // 省略代码无数 
 state = 0; 
 } 
} 
```

### **什么是可重入锁**

如果你细心观察，会发现我们创建的锁的具体类名是 ReentrantLock，这个翻译过来叫**可重入锁**，这个概念前面我们一直没有介绍过。**所谓可重入锁，顾名思义，指的是线程可以重复获取同 一把锁**。例如下面代码中，当线程 T1 执行到 ① 处时，已经获取到了锁 rtl ，当在 ① 处调用 get() 方法时，会在 ② 再次对锁 rtl 执行加锁操作。此时，如果锁 rtl 是可重入的，那么线程 T1 可以再次加锁成功；如果锁 rtl 是不可重入的，那么线程 T1 此时会被阻塞。 



除了可重入锁，可能你还听说过可重入函数，可重入函数怎么理解呢？指的是线程可以重复调 用？显然不是，所谓**可重入函数，指的是多个线程可以同时调用该函数**，每个线程都能得到正确 结果；同时在一个线程内支持线程切换，无论被切换多少次，结果都是正确的。多线程可以同时 执行，还支持线程切换，这意味着什么呢？线程安全啊。所以，可重入函数是线程安全的。

### **公平锁与非公平锁**

在使用 ReentrantLock 的时候，你会发现 ReentrantLock 这个类有两个构造函数，一个是无参 构造函数，一个是传入 fair 参数的构造函数。fair 参数代表的是锁的公平策略，如果传入 true 就表示需要构造一个公平锁，反之则表示要构造一个非公平锁。 

```java
// 无参构造函数：默认非公平锁 
public ReentrantLock() { 
 sync = new NonfairSync(); 
} 

// 根据公平策略参数创建锁 
public ReentrantLock(boolean fair){ 
 sync = fair ? new FairSync(): new NonfairSync(); 
} 
```

锁都对应着一个等待 队列，如果一个线程没有获得锁，就会进入等待队列，当有线程释放锁的时候，就需要从等待队 列中唤醒一个等待的线程。**如果是公平锁，唤醒的策略就是谁等待的时间长，就唤醒谁，很公 平；如果是非公平锁，则不提供这个公平保证，有可能等待时间短的线程反而先被唤醒。**

### **用锁的最佳实践**

Doug Lea《Java 并发编程：设计原则与模式》一书中，推荐的三个用锁的最佳实践，它们分别是：

1. 永远只在更新对象的成员变量时加锁

2. 永远只在访问可变的成员变量时加锁

3. 永远不在调用其他对象的方法时加锁

这三条规则，前两条估计你一定会认同，最后一条你可能会觉得过于严苛。但是我还是倾向于你去遵守，因为调用其他对象的方法，实在是太不安全了，也许“其他”方法里面有线程 sleep()的调用，也可能会有奇慢无比的 I/O 操作，这些都会严重影响性能。更可怕的是，“其他”类的方法可能也会加锁，然后双重加锁就可能导致死锁。



---



## 15 | Lock和Condition（下）：Dubbo如何用管程实现异步转同步？

**Condition 实现了管程模型里面的条件变量**。

### **同步与异步**

**通俗点来讲就是调用方是否需要等待结果，如果需要等待结果，就是同步；如果不需要等待结果，就是异步**。



---



## 16 | Semaphore：如何快速实现一个限流器？

Semaphore，现在普遍翻译为“信号量”，以前也曾被翻译成“信号灯”，因为类似现实生活里 的红绿灯，车辆能不能通行，要看是不是绿灯。同样，在编程世界里，线程能不能执行，也要看 信号量是不是允许。 

### 信号量模型

信号量模型还是很简单的，可以简单概括为：**一个计数器，一个等待队列，三个方法**。在信号量 模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它 们，这三个方法分别是：init()、down() 和 up()。

![1564808392725](/img/assets_2019/1564808392725.png)

这三个方法详细的语义具体如下所示。 

- init()：设置计数器的初始值。 

- down()：计数器的值减 1；如果此时计数器的值小于 0，则当前线程将被阻塞，否则当前线程 可以继续执行。 

- up()：计数器的值加 1；如果此时计数器的值小于或者等于 0，则唤醒等待队列中的一个线程，并将其从等待队列

  ```
  
  ```

  中移除。 



这里提到的 init()、down() 和 up() 三个方法都是原子性的，并且这个原子性是由信号量模型的 实现方保证的。在 Java SDK 里面，信号量模型是由 java.util.concurrent.Semaphore 实现的， Semaphore 这个类能够保证这三个方法都是原子操作。

 这里再插一句，信号量模型里面，down()、up() 这两个操作历史上最早称为 P 操作和 V 操作，所以信号量模型也被称为 PV 原语。另外，还有些人喜欢用 semWait() 和 semSignal() 来称呼它们，虽然叫法不同，但是语义都是相同的。在 Java SDK 并发包里，down() 和 up() 对应的则是acquire() 和 release()。

### 如何使用信号量

其实很简单，就像我们用互斥锁一样，只需要在进入临界区之前执行一下 down() 操作，退出临 界区之前执行一下 up() 操作就可以了。下面是 Java 代码的示例，acquire() 就是信号量里的down() 操作，release() 就是信号量里的 up() 操作。

```java
static int count; 
// 初始化信号量 
static final Semaphore s   = new Semaphore(1); 
// 用信号量保证互斥  
static void addOne() { 
 s.acquire(); 
 try { 
 count+=1; 
 } finally { 
 s.release(); 
 } 
}
```

下面我们再来分析一下，信号量是如何保证互斥的。假设两个线程 T1 和 T2 同时访问 addOne() 方法，当它们同时调用 acquire() 的时候，由于 acquire() 是一个原子操作，所以只能有一个线 程（假设 T1）把信号量里的计数器减为 0，另外一个线程（T2）则是将计数器减为 -1。对于线 程 T1，信号量里面的计数器的值是 0，大于等于 0，所以线程 T1 会继续执行；对于线程 T2，信 号量里面的计数器的值是 -1，小于 0，按照信号量模型里对 down() 操作的描述，线程 T2 将被阻塞。所以此时只有线程 T1 会进入临界区执行count+=1；。 

当线程 T1 执行 release() 操作，也就是 up() 操作的时候，信号量里计数器的值是 -1，加 1 之后 的值是 0，小于等于 0，按照信号量模型里对 up() 操作的描述，此时等待队列中的 T2 将会被唤 醒。于是 T2 在 T1 执行完临界区代码之后才获得了进入临界区执行的机会，从而保证了互斥 性。 

### 快速实现一个限流器

上面的例子，我们用信号量实现了一个最简单的互斥锁功能。估计你会觉得奇怪，既然有 Java SDK 里面提供了 Lock，为啥还要提供一个 Semaphore ？其实实现一个互斥锁，仅仅是 Semaphore 的部分功能，Semaphore 还有一个功能是 Lock 不容易实现的，那就是： **Semaphore 可以允许多个线程访问一个临界区**。

现实中还有这种需求？有的。比较常见的需求就是我们工作中遇到的各种池化资源，例如连接 池、对象池、线程池等等。其中，你可能最熟悉数据库连接池，在同一时刻，一定是允许多个线 程同时使用连接池的，当然，每个连接在被释放前，是不允许其他线程使用的。 



---



## 17 | ReadWriteLock：如何快速实现一个完备的缓存？

理论上用这两个同步原语中 任何一个都可以解决所有的并发问题。那 Java SDK 并发包里为什么还有很多其他的工具类呢？原因很简单：**分场景优化性能，提升易用性**。 

今天我们就介绍一种非常普遍的并发场景：读多写少场景。实际工作中，为了优化性能，我们经 常会使用缓存，例如缓存元数据、缓存基础数据等，这就是一种典型的读多写少应用场景。

针对读多写少这种并发场景，Java SDK 并发包提供了读写锁——ReadWriteLock，非常容易使 用，并且性能很好。 

### 那什么是读写锁呢？

读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条 

基本原则： 

1. 允许多个线程同时读共享变量； 

2. 只允许一个线程写共享变量； 

3. 如果一个写线程正在执行写操作，此时禁止读线程读共享变量。 

读写锁与互斥锁的一个重要区别就是**读写锁允许多个线程同时读共享变量**，而互斥锁是不允许 的，这是读写锁在读多写少场景下性能优于互斥锁的关键。但**读写锁的写操作是互斥的**，当一个线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。 

### 快速实现一个缓存

ReadWriteLock 是一个接口，它的实现类是 ReentrantReadWriteLock，通过名字你应该就能判断出来，它是支持可重入 的。





读写锁类似于 ReentrantLock，也支持公平模式和非公平模式。读锁和写锁都实现l了java.util. concurrent. locks. Lock 接口，所以除了支持 lock() 方法外，tryLock()、 lockInterruptibly() 等方法也都是支持的。但是有一点需要注意，那就是只有写锁支持条件变量， 读锁是不支持条件变量的，读锁调用 newCondition() 会抛出 UnsupportedOperationException 异常。 

今天我们用 ReadWriteLock 实现了一个简单的缓存，这个缓存虽然解决了缓存的初始化问题，但 是没有解决缓存数据与源头数据的同步问题，这里的数据同步指的是保证缓存数据和源头数据的 一致性。解决数据同步问题的一个最简单的方案就是**超时机制**。所谓超时机制指的是加载进缓存 的数据不是长久有效的，而是有时效的，当缓存的数据超过时效，也就是超时之后，这条数据在 缓存中就失效了。而访问缓存中失效的数据，会触发缓存重新从源头把数据加载进缓存。 

当然也可以在源头数据发生变化时，快速反馈给缓存，但这个就要依赖具体的场景了。例如 MySQL 作为数据源头，可以通过近实时地解析 binlog 来识别数据是否发生了变化，如果发生了 变化就将最新的数据推送给缓存。另外，还有一些方案采取的是数据库和缓存的双写方案。 

 

## 18 | StampedLock：有没有比读写锁更快的锁？

Java 在 1.8 这个版本里，提供了一种叫 StampedLock 的锁，它的性能就比读写锁还要好。

ReadWriteLock 支持两种模式：一种是读锁，一种是写锁。而 StampedLock 支持三种模式，分别 是：**写锁**、**悲观读锁**和**乐观读**。其中，写锁、悲观读锁的语义和 ReadWriteLock 的写锁、读锁的 语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读 锁是互斥的。

不同的是：StampedLock 里的写锁和悲观读锁加锁成功之后，都会返回一个 stamp；然后解锁的时候，需要传入这个 stamp。相关的示例代码如下。 

```java
final StampedLock sl = new StampedLock(); 
// 获取 / 释放悲观读锁⽰意代码 
long stamp = sl.readLock(); 
try { 
 // 省略业务相关代码 
} finally { 
 sl.unlockRead(stamp); 
} 
// 获取 / 释放写锁⽰意代码 
long stamp = sl.writeLock(); 
try { 
 // 省略业务相关代码 
} finally { 
 sl.unlockWrite(stamp); 
} 
```

StampedLock 的性能之所以比 ReadWriteLock 还要好，其关键是 StampedLock 支持乐观读的方 式。ReadWriteLock 支持多个线程同时读，但是当多个线程同时读的时候，所有的写操作会被阻 塞；而 StampedLock 提供的乐观读，是允许一个线程获取写锁的，也就是说不是所有的写操作 都被阻塞。 

注意这里，我们用的是“乐观读”这个词，而不是“乐观读锁”，是要提醒你，**乐观读这个操作是无锁的**，所以相比较 ReadWriteLock 的读锁，乐观读的性能更好一些。 



### StampedLock 使用注意事项

对于读多写少的场景 StampedLock 性能很好，简单的应用场景基本上可以替代 ReadWriteLock， 但是**StampedLock 的功能仅仅是 ReadWriteLock 的子集**，在使用的时候，还是有几个地方需要注 意一下。 



StampedLock 在命名上并没有增加 Reentrant，想必你已经猜测到 StampedLock 应该是不可重 入的。事实上，的确是这样的，**StampedLock 不支持重入**。这个是在使用中必须要特别注意的。 



另外，StampedLock 的悲观读锁、写锁都不支持条件变量，这个也需要你注意。 



还有一点需要特别注意，那就是：如果线程阻塞在 StampedLock 的 readLock() 或者 writeLock() 上时，此时调用该阻塞线程的 interrupt() 方法，会导致 CPU 飙升。例

所以，**使用 StampedLock 一定不要调用中断操作，如果需要支持中断功能，一定使用可中断的悲观读锁 readLockInterruptibly() 和写锁 writeLockInterruptibly()**。这个规则一定要记清楚。 

#### 总结

StampedLock 的使用看上去有点复杂，但是如果你能理解乐观锁背后的原理，使用起来还是比较 流畅的。建议你认真揣摩 Java 的官方示例，这个示例基本上就是一个最佳实践。我们把 Java 官 方示例精简后，形成下面的代码模板，建议你在实际工作中尽量按照这个模板来使用 StampedLock。 

StampedLock 读模板： 

```java
 final StampedLock sl =  
 new StampedLock(); 
// 乐观读 
long stamp =  sl.tryOptimisticRead(); 
// 读⼊⽅法局部变量 
..... 
// 校验 stamp 
if (!sl.validate(stamp)){ 
 // 升级为悲观读锁 
 stamp = sl.readLock(); 
 try { 
 // 读⼊⽅法局部变量 
 ..... 
 } finally { 
 // 释放悲观读锁 
 sl.unlockRead(stamp); 
 } 
} 
// 使⽤⽅法局部变量执⾏业务操作 
...... 
```

StampedLock 写模板：

```java
long stamp = sl.writeLock(); 
try { 
 // 写共享变量 
 ...... 
} finally { 
 sl.unlockWrite(stamp); 
} 
```



---



## 19 | CountDownLatch和CyclicBarrier：如何让多线程 步调一致？ 

```java
while(存在未对账订单){ 
// 查询未对账订单 
Thread T1 = new Thread(()->{ pos = getPOrders(); }); 
T1.start(); 
// 查询派送单 
Thread T2 = new Thread(()->{ dos = getDOrders(); }); 
T2.start(); 
// 等待 T1、T2 结束 
T1.join(); 
T2.join(); 
// 执⾏对账操作 
diff = check(pos, dos); 
// 差异写⼊差异库 
save(diff); 
}
```

```java
// 创建 2 个线程的线程池 
Executor executor = Executors.newFixedThreadPool(2); 
while(存在未对账订单){ 
// 查询未对账订单 
executor.execute(()-> { pos = getPOrders(); }); 
// 查询派送单 
executor.execute(()-> { dos = getDOrders(); }); 
/* ？？如何实现等待？？*/ 
// 执⾏对账操作 
diff = check(pos, dos); 
// 差异写⼊差异库 
save(diff); 
} 
```

那如何解决这个问题呢？你可以开动脑筋想出很多办法，最直接的办法是弄一个计数器，初始值 设置成 2，当执行完pos = getPOrders(); 

这个操作之后将计数器减 1，执行完dos = getDOrders(); 之后也将计数器减 1，在主线程 里，等待计数器等于 0；当计数器等于 0 时，说明这两个查询操作执行完了。等待计数器等于 0 其实就是一个条件变量，用管程实现起来也很简单。 

不过我并不建议你在实际项目中去实现上面的方案，因为 Java 并发包里已经提供了实现类似功能的工具类**CounttDownLatch**，我们直接使用就可以了。下面的代码示例中，在 while 循环里面，我们首先创建了一个 CountDownLatch，计数器的初始值等于 2，之后在pos = getPOrders(); 

和dos = getDOrders(); 两条语句的后面对计数器执行减 1 操作，这个对计数器减 1 的操作 是通过调用 latch.countDown(); 来实现的。在主线程中，我们通过调用 latch.await() 来实现对计数器等于 0 的等待。 

```java
// 创建 2 个线程的线程池 
Executor executor =Executors.newFixedThreadPool(2); 
while(存在未对账订单){ 
// 计数器初始化为 2 
CountDownLatch latch = new CountDownLatch(2); 
// 查询未对账订单 
executor.execute(()-> { 
pos = getPOrders(); 
latch.countDown(); 
}); 
// 查询派送单 
executor.execute(()-> { 
dos = getDOrders(); 
latch.countDown(); 
}); 
// 等待两个查询操作结束 
latch.await(); 
// 执⾏对账操作 
diff = check(pos, dos); 
// 差异写⼊差异库 
save(diff); 
}
```

前面我们将 getPOrders() 和 getDOrders() 这两个查询操作并行了，但这两个查询操作和对账操 

作 check()、save() 之间还是串行的。很显然，这两个查询操作和对账操作也是可以并行的，也就 

是说，在执行对账操作的时候，可以同时去执行下一轮的查询操作，这个过程可以形象化地表述 

为下面这幅示意图。 

![1564815586081](/img/assets_2019/1564815586081.png)

那接下来我们再来思考一下如何实现这步优化，两次查询操作能够和对账操作并行，对账操作还 依赖查询操作的结果，这明显有点生产者 - 消费者的意思，两次查询操作是生产者，对账操作是 消费者。既然是生产者 - 消费者模型，那就需要有个队列，来保存生产者生产的数据，而消费者 则从这个队列消费数据。 

不过针对对账这个项目，我设计了两个队列，并且两个队列的元素之间还有对应关系。具体如下 图所示，订单查询操作将订单查询结果插入订单队列，派送单查询操作将派送单插入派送单队 列，这两个队列的元素之间是有一一对应的关系的。两个队列的好处是，对账操作可以每次从订 单队列出一个元素，从派送单队列出一个元素，然后对这两个元素执行对账操作，这样数据一定 不会乱掉。 

![1564815632608](/img/assets_2019/1564815632608.png)

下面再来看如何用双队列来实现完全的并行。一个最直接的想法是：一个线程 T1 执行订单的查 询工作，一个线程 T2 执行派送单的查询工作，当线程 T1 和 T2 都各自生产完 1 条数据的时候， 通知线程 T3 执行对账操作。这个想法虽看上去简单，但其实还隐藏着一个条件，那就是线程 T1 和线程 T2 的工作要步调一致，不能一个跑得太快，一个跑得太慢，只有这样才能做到各自生产 完 1 条数据的时候，通知线程 T3。 

下面这幅图形象地描述了上面的意图：线程 T1 和线程 T2 只有都生产完 1 条数据的时候，才能一 起向下执行，也就是说，线程 T1 和线程 T2 要互相等待，步调要一致；同时当线程 T1 和 T2 都生 产完一条数据的时候，还要能够通知线程 T3 执行对账操作。

![1564815674720](/img/assets_2019/1564815674720.png)

下面我们就来实现上面提到的方案。这个方案的难点有两个：一个是线程 T1 和 T2 要做到步调一 致，另一个是要能够通知到线程 T3。 

你依然可以利用一个计数器来解决这两个难点，计数器初始化为 2，线程 T1 和 T2 生产完一条数 据都将计数器减 1，如果计数器大于 0 则线程 T1 或者 T2 等待。如果计数器等于 0，则通知线程 T3，并唤醒等待的线程 T1 或者 T2，与此同时，将计数器重置为 2，这样线程 T1 和线程 T2 生产 下一条数据的时候就可以继续使用这个计数器了。 

同样，还是建议你不要在实际项目中这么做，因为 Java 并发包里也已经提供了相关的工具类：**CyclicBarrier**。在下面的代码中，我们首先创建了一个计数器初始值为 2 的 CyclicBarrier， 你需要注意的是创建 CyclicBarrier 的时候，我们还传入了一个回调函数，当计数器减到 0 的时候，会调用这个回调函数。 

线程 T1 负责查询订单，当查出一条时，调用 barrier.await() 

来将计数器减 1，同时等待计数器变成 0；线程 T2 负责查询派送单，当查出一条时，也调用 barrier.await() 来将计数器减 1，同时等待计数器变成 0；当 T1 和 T2 都调用 barrier.await() 的时候，计数器会减到 0，此时 T1 和 T2 就可以执行下一条语句了，同时 会调用 barrier 的回调函数来执行对账操作。 

非常值得一提的是，CyclicBarrier 的计数器有自动重置的功能，当减到 0 的时候，会自动重置你设置的初始值。这个功能用起来实在是太方便了。 

```java
// 订单队列 
Vector pos; 
// 派送单队列 
Vector dos; 
// 执⾏回调的线程池 
Executor executor = Executors.newFixedThreadPool(1); 
final CyclicBarrier barrier = new CyclicBarrier(2, ()->{ 
executor.execute(()->check()); 
}); 

void check(){ 
P p = pos.remove(0); 
D d = dos.remove(0); 
// 执⾏对账操作 
diff = check(p, d); 
// 差异写⼊差异库 
save(diff); 
} 

void checkAll(){ 
// 循环查询订单库 
Thread T1 = new Thread(()->{ 
while(存在未对账订单){ 
// 查询订单库 
pos.add(getPOrders()); 
// 等待 
barrier.await(); 
} 
} 

T1.start(); 

// 循环查询运单库 

Thread T2 = new Thread(()->{ 
while(存在未对账订单){ 
// 查询运单库 
dos.add(getDOrders()); 
// 等待 
barrier.await(); 
} 

} 

T2.start(); 

} 
```

#### 总结

CountDownLatch 和 CyclicBarrier 是 Java 并发包提供的两个非常易用的线程同步工具类，这两个 工具类用法的区别在这里还是有必要再强调一下：CountDownLatch 主要用来解决一个线程等待多个线程的的场景，可以类比旅游团团长要等待所有的游客到齐才能去下一个景点；而CyclicBarrier 一一组线程之间互相等待，更像是几个驴友之间不离不弃。除此之外 CountDownLatch 的计数器是不能循环利用的，也就是说一旦计数器减到 0，再有线程调用 await()，该线程会直接通过。但CyclicBarrier 的计数器是可以循环利用的，而且具备自动重置的功能，一旦计数器减到 0 会自动重置到你设置的初始值。除此之外，CyclicBarrier 还可以设置回调函数，可以说是功能丰富。 



---



## 20	|	并发容器：都有哪些“坑”需要我们填？

Java并发包有很大一部分内容都是关于并发容器的，因此学习和搞懂这部分的内容很有必要。

Java1.5之前提供的同步容器虽然也能保证线程安全，但是性能很差，而Java1.5版本之后提供 的并发容器在性能方面则做了很多优化，并且容器的类型也更加丰富了。下面我们就对比二者来学习这部分的内容。 

Java中的容器主要可以分为四个大类，分别是	List、Map、Set	和	Queue，但并不是所有的	Java 容器都是线程安全的。例如，我们常用的	ArrayList、HashMap	就不是线程安全的。在介绍线程安全的容器之前，我们先思考这样一个问题：如何将非线程安全的容器变成线程安全的容器？

Java SDK 的开发人员也想到了，所以他们在 Collections 这个类中还提供了一套完备的包装类，比如下面的示例代码中，分别把 ArrayList、 HashSet 和 HashMap 包装成了线程安全的 List、Set 和 Map。 

```java
List list = Collections. synchronizedList(new ArrayList()); 

Set set = Collections. synchronizedSet(new HashSet()); 

Map map = Collections. synchronizedMap(new HashMap()); 
```

在容器领域一个容易被忽视的“坑”是用迭代器遍历容器,而正确做法是下面这样，锁住 list 之后再执行遍历操作。如果你查看 Collections 内部的包装类源 码，你会发现包装类的公共方法锁的是对象的 this，其实就是我们这里的 list，所以锁住 list 绝对 是线程安全的。 

```java
List list =	Collections.synchronizedList(new ArrayList());
synchronized(list)	{		 
	Iterator i = list.iterator();	 
	while(i.hasNext()) 		
        foo(i.next()); 

}		
```

上面我们提到的这些经过包装后线程安全容器，都是基于synchronized这个同步关键字实现的，所以也被称为同步容器。Java提供的同步容器还有Vector、Stack和Hashtable，这三个容器不是基于包装类实现的，但同样是基于synchronized实现的，对这三个容器的遍历，同样要加锁保证互斥。

Java在1.5版本之前所谓的线程安全的容器，主要指的就是同步容器。不过同步容器有个最大的 问题，那就是性能差，所有方法都用	synchronized	来保证互斥，串行度太高了。因此Java在1.5及之后版本提供了性能更高的容器，我们一般称为并发容器。 并发容器虽然数量非常多，但依然是前面我们提到的四大类：List、Map、Set和Queue，下面的 并发容器关系图，基本上把我们经常用的容器都覆盖到了。 

![1564816783370](/img/assets_2019/1564816783370.png)

鉴于并发容器的数量太多，再加上篇幅限制，所以我并不会一一详细介绍它们的用法，只是把关键点介绍一下。 

**（一）List**

List里面只有一个实现类就是CopyOnWriteArrayList。CopyOnWrite，顾名思义就是写的时候会 将共享变量新复制一份出来，这样做的好处是读操作完全无锁。 

那CopyOnWriteArrayList的实现原理是怎样的呢？下面我们就来简单介绍一下

CopyOnWriteArrayList内部维护了一个数组，成员变量array就指向这个内部数组，所有的读操作都是基于	array进行的，如下图所示，迭代器Iterator遍历的就是array数组。 

如果在遍历 array 的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList 是如何处理 的呢？CopyOnWriteArrayList 会将 array 复制一份，然后在新复制处理的数组上执行增加元素的 操作，执行完之后再将 array 指向这个新的数组。通过下图你可以看到，读写是可以并行的，遍 历操作一直都是基于原 array 执行，而写操作则是基于新 array 进行。 

![1564816916089](/img/assets_2019/1564816916089.png)

使用 CopyOnWriteArrayList 需要注意的“坑”主要有两个方面。一个是应用场景， CopyOnWriteArrayList 仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致。例如上 面的例子中，写入的新元素并不能立刻被遍历到。另一个需要注意的是，CopyOnWriteArrayList 迭代器是只读的，不支持增删改。因为迭代器遍历的仅仅是一个快照，而对快照进行增删改是没 有意义的。 

**（二）Map**

Map 接口的两个实现是 ConcurrentHashMap 和 ConcurrentSkipListMap，它们从应用的角度来 看，主要区别在于ConcurrentHashMap 的的 key 是无序的，，而 ConcurrentSkipListMap的 key 是有序的。所以如果你需要保证 key 的顺序，就只能使用 ConcurrentSkipListMap。

**使用 ConcurrentHashMap 和 ConcurrentSkipListMap 需要注意的地方是，它们的 key 和 value 都不能为空，否则会抛出NullPointerException**

![1564816998433](/img/assets_2019/1564816998433.png)

ConcurrentSkipListMap	里面的	SkipList	本身就是一种数据结构，中文一般都翻译为“跳表”。 跳表插入、删除、查询操作平均的时间复杂度是	O(log	n)，理论上和并发线程数没有关系，所以 在并发度非常高的情况下，若你对	ConcurrentHashMap	的性能还不满意，可以尝试一下 ConcurrentSkipListMap。

**（三）Set** 

Set接口的两个实现是CopyOnWriteArraySet和ConcurrentSkipListSet，使用场景可以参考前面 讲述的	CopyOnWriteArrayList和ConcurrentSkipListMap，它们的原理都是一样的，这里就不再赘述了。 

**（四）Queue** 

Java并发包里面Queue这类并发容器是最复杂的，你可以从以下两个维度来分类。一个维度是 阻塞与非阻塞，所谓阻塞指的是当队列已满时，入队操作阻塞；当队列已空时，出队操作阻塞。 另一个维度是单端与双端，单端指的是只能队尾入队，队首出队；而双端指的是队首队尾皆可入队出队。Java并发包里阻塞队列都用Blocking关键字标识，单端队列使用Queue标识，双端队列使用Deque标识。 

1.单端阻塞队列：其实现有	ArrayBlockingQueue、LinkedBlockingQueue、 SynchronousQueue、LinkedTransferQueue、PriorityBlockingQueue和DelayQueue。内部一般会持有一个队列，这个队列可以是数组（其实现是ArrayBlockingQueue）也可以是链表（其实 现是LinkedBlockingQueue）；甚至还可以不持有队列（其实现是SynchronousQueue），此时生产者线程的入队操作必须等待消费者线程的出队操作。而LinkedTransferQueue融合 LinkedBlockingQueue和SynchronousQueue的功能，性能比LinkedBlockingQueue	更好； PriorityBlockingQueue	支持按照优先级出队；DelayQueue	支持延时出队。 

![1564817180550](/img/assets_2019/1564817180550.png)

2.双双端端阻阻塞塞队队列列：其实现是 LinkedBlockingDeque。

![1564817196357](/img/assets_2019/1564817196357.png)

3.单端非阻塞队列：实现是 ConcurrentLinkedQueue。 

4.双端非阻塞队列：实现是 ConcurrentLinkedDeque。

另外，使用队列时，需要格外注意队列是否支持有界（所谓有界指的是内部的队列是否有容量限制）。实际工作中，一般都不建议使用无界的队列，因为数据量大了之后很容易导致 OOM。上 面我们提到的这些 Queue 中，只有 ArrayBlockingQueue 和 LinkedBlockingQueue 是支持有界的，所以**在使用其他无界队列时，一定要充分考虑是否存在导致 OOM 的隐患。** 

#### 总结

Java 并发容器的内容很多，但鉴于篇幅有限，我们只是对一些关键点进行了梳理和介绍。 而在实际工作中，你不单要清楚每种容器的特性，还要能选选对对容容器器，，这这才才是是关关键键，至于每种容器 的用法，用的时候看一下 API 说明就可以了，这些容器的使用都不难。在文中，我们甚至都没有介绍 Java 容器的快速失败机制（Fail-Fast），原因就在于当你选对容器的时候，根本不会触发它。 

**线上系统 CPU 突然飙升，你怀疑有同学在并发场景里使用了 HashMap，因为在 1.8 之前的版本 里并发执行 HashMap.put() 可能会导致 CPU 飙升到 100%，你觉得该如何验证你的猜测呢？** 

Java7中的HashMap在执行put操作时会涉及到扩容，由于扩容时链表并发操作会造成链表成环，所以可 

能导致cpu飙升100%。 



---



